{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd38c0ce-ff45-4072-8ac4-779a574e2883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## \n",
    "- **Usage**: Interactive development and ad hoc analysis\n",
    "- **Management**: Manged by the user via UI, CLI or API REST\n",
    "- **Termination**: Manual or Auto-termination after inactivity. 120 min (default), 10 min (minimun)\n",
    "- **Cost efficiency**: cost more to run when compared to job and sql warehouse pro. $0.65 per DBU classic and $0.95 per DBU serveless \n",
    "    https://www.databricks.com/product/pricing/datascience-ml\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52b46ac2-ac92-4cf4-b227-7a0d2c25b81b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "---\n",
    "\n",
    "##  Serveless Compute for Notebooks\n",
    "- On demand\n",
    "- Auto scalable\n",
    "- Run SQL and Python\n",
    "- No infra\n",
    "- Budget Policies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ef5c1dd-42b7-4579-9808-e6069445d9ac",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "create all purpose cluster"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "print(\"Attempting to create cluster. Please wait...\")\n",
    "\n",
    "c = w.clusters.create_and_wait(\n",
    "  cluster_name             = 'my-cluster',\n",
    "  spark_version            = '13.3.x-scala2.12',\n",
    "  node_type_id             = 'i3.xlarge',\n",
    "  autotermination_minutes  = 15,\n",
    "  num_workers              = 1\n",
    ")\n",
    "\n",
    "print(f\"The cluster is now ready at \" \\\n",
    "      f\"{w.config.host}#setting/clusters/{c.cluster_id}/configuration\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cd51f71-3b4b-4549-b146-423d8913bc30",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "list all all purpose cluster"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    " \n",
    "for c in w.clusters.list():\n",
    "  print(c.cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "037b53b0-0a90-4032-9249-07ab7dfd2091",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Identify cost of all purpose clusters this month vs last month"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fce54bea-0288-490e-bd84-8302fd9f87f5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "most used node types in workspace"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with node_counts as\n",
    "(SELECT\n",
    "    driver_node_type as node_type, 1 as node_count\n",
    "  FROM\n",
    "    system.compute.clusters\n",
    "WHERE \n",
    "workspace_id = dataops_prd.libs.get_workspace_id()\n",
    "UNION ALL\n",
    "SELECT\n",
    "    worker_node_type as node_type, coalesce(worker_count,max_autoscale_workers) as node_count\n",
    "  FROM\n",
    "    system.compute.clusters\n",
    "WHERE workspace_id = dataops_prd.libs.get_workspace_id()\n",
    ")\n",
    "select node_type, sum(node_count) as count\n",
    "FROM\n",
    "    node_counts\n",
    "GROUP BY ALL\n",
    "ORDER BY count DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a64e20a5-d3d6-4c1c-a7cd-70e3d1eff7ee",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "most used node type not associated with pools"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with node_counts as\n",
    "(SELECT\n",
    "    driver_node_type as node_type, 1 as node_count\n",
    "  FROM\n",
    "    system.compute.clusters\n",
    "WHERE \n",
    "workspace_id = dataops_prd.libs.get_workspace_id() AND driver_instance_pool_id is null\n",
    "UNION ALL\n",
    "SELECT\n",
    "    worker_node_type as node_type, coalesce(worker_count,max_autoscale_workers) as node_count\n",
    "  FROM\n",
    "    system.compute.clusters \n",
    "WHERE workspace_id = dataops_prd.libs.get_workspace_id() and worker_instance_pool_id is null\n",
    ")\n",
    "select node_type, sum(node_count) as count\n",
    "FROM\n",
    "    node_counts\n",
    "GROUP BY ALL\n",
    "ORDER BY count DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed410301-a4ca-4784-9ca1-3cb5170d0aca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Managing cluster logs\n",
    "- **Event log**: records all significant actions related to the cluster, such as when the cluster was created, terminated, edited, scalated or encontered any erros\n",
    "- **Spark UI**: interface for monitoring and debugging job execution, stages and tasks\n",
    "- **Driver logs**: outputs from the notebooks and libraries"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8769107896723891,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "All Purpose",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
